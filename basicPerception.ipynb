{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab38243",
   "metadata": {},
   "source": [
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mettinger/activeInference/blob/main/hiddenMarkov.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca9e21d",
   "metadata": {},
   "source": [
    "*Note*: When running this notebook in Google Colab, you may have to run `!pip install pyro-ppl`. The cell below is commented out in case you are running this notebook locally with Pyro already installed.  For use on Colab uncomment the cell and run.  After Colab installs Pyro, you may need to restart the Colab runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b70b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install pyro-ppl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "620fa4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "import pyro.distributions as dist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde8b80",
   "metadata": {},
   "source": [
    "### Specify the true data generation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62392c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: \n",
      "[0 1 0 0 1 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "numStates = 6\n",
    "numOutcomes = 6\n",
    "numObservations = 10\n",
    "trueDistribution = np.array([.5,.5,0,0,0,0])\n",
    "\n",
    "seed = 17\n",
    "np.random.seed(seed) # for reproducibility\n",
    "\n",
    "likelihoodMatrix = np.eye(6)\n",
    "observationDistribution = np.dot(likelihoodMatrix, trueDistribution)\n",
    "\n",
    "observations = np.random.choice(numOutcomes, size=numObservations, replace=True, p=observationDistribution)\n",
    "print(\"Observations: \")\n",
    "print(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42104f1d",
   "metadata": {},
   "source": [
    "### Define various models and guides.  \"Guide\" is the Pyro terminology for the variational distribution which approximates the true posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "419358fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the param store in case we're in a REPL\n",
    "pyro.clear_param_store()\n",
    "\n",
    "def modelAccurate(data):\n",
    "    # loop over the observed data\n",
    "    for i in range(len(data)):\n",
    "        pyro.sample(\"obs_{}\".format(i), dist.Categorical(trueDistribution), obs=data[i])\n",
    "\n",
    "def guideAccurate(data):\n",
    "    # register the two variational parameters with Pyro\n",
    "    # - both parameters will have initial value 15.0.\n",
    "    # - because we invoke constraints.positive, the optimizer\n",
    "    # will take gradients on the unconstrained parameters\n",
    "    # (which are related to the constrained parameters by a log)\n",
    "    alpha_q = pyro.param(\"alpha_q\", torch.tensor(15.0),\n",
    "                         constraint=constraints.positive)\n",
    "    beta_q = pyro.param(\"beta_q\", torch.tensor(15.0),\n",
    "                        constraint=constraints.positive)\n",
    "    # sample latent_fairness from the distribution Beta(alpha_q, beta_q)\n",
    "    pyro.sample(\"latent_fairness\", dist.Beta(alpha_q, beta_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05e3d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelAccurate\n",
    "guide = guideAccurate\n",
    "\n",
    "# setup the optimizer\n",
    "adam_params = {\"lr\": 0.0005, \"betas\": (0.90, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "n_steps = 1000\n",
    "# do gradient steps\n",
    "for step in range(n_steps):\n",
    "    svi.step(data)\n",
    "    if step % 100 == 0:\n",
    "        print(str(step) + '\\n', end='')\n",
    "\n",
    "# grab the learned variational parameters\n",
    "alpha_q = pyro.param(\"alpha_q\").item()\n",
    "beta_q = pyro.param(\"beta_q\").item()\n",
    "\n",
    "# here we use some facts about the Beta distribution\n",
    "# compute the inferred mean of the coin's fairness\n",
    "inferred_mean = alpha_q / (alpha_q + beta_q)\n",
    "# compute inferred standard deviation\n",
    "factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q))\n",
    "inferred_std = inferred_mean * math.sqrt(factor)\n",
    "\n",
    "print(\"\\nBased on the data and our prior belief, the fairness \" +\n",
    "      \"of the coin is %.3f +- %.3f\" % (inferred_mean, inferred_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447ad11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
